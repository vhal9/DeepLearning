{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de imagens com 10 objetos diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregar base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setar o tipo das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_treinamento = x_train.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_teste = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduzir a escala dos valores dos pixel\n",
    "- escala de 0 a 1\n",
    "- divisao por 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_treinamento /= 255\n",
    "previsores_teste /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação dos valores das classes para valores categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_treinamento = np_utils.to_categorical(y_train, 10)\n",
    "classe_teste  = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrutura da Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = Sequential()\n",
    "#primeira camada de convolução\n",
    "classificador.add(Conv2D(32, (3,3), input_shape=(32,32,3), activation = 'relu'))\n",
    "classificador.add(BatchNormalization())\n",
    "classificador.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#segunda camada de convolução\n",
    "classificador.add(Conv2D(32, (3,3), input_shape=(32,32,3), activation = 'relu'))\n",
    "classificador.add(BatchNormalization())\n",
    "classificador.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#Flatten para transformar a matriz num vetor\n",
    "classificador.add(Flatten())\n",
    "\n",
    "\n",
    "classificador.add(Dense(units=128, activation = 'relu'))\n",
    "classificador.add(Dropout(0.2))\n",
    "classificador.add(Dense(units=128, activation = 'relu'))\n",
    "classificador.add(Dropout(0.2))\n",
    "classificador.add(Dense(units=128, activation = 'relu'))\n",
    "classificador.add(Dropout(0.2))\n",
    "\n",
    "classificador.add(Dense(units=10, activation='softmax'))\n",
    "classificador.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 298s 6ms/step - loss: 1.6115 - accuracy: 0.4175 - val_loss: 1.9957 - val_accuracy: 0.3121\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 304s 6ms/step - loss: 1.2366 - accuracy: 0.5650 - val_loss: 1.4233 - val_accuracy: 0.5085\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 1.0723 - accuracy: 0.6253 - val_loss: 1.4570 - val_accuracy: 0.4960\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 263s 5ms/step - loss: 0.9618 - accuracy: 0.6642 - val_loss: 1.0359 - val_accuracy: 0.6435\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 265s 5ms/step - loss: 0.8772 - accuracy: 0.6959 - val_loss: 0.9904 - val_accuracy: 0.6522\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 267s 5ms/step - loss: 0.8053 - accuracy: 0.7200 - val_loss: 0.9481 - val_accuracy: 0.6704\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 264s 5ms/step - loss: 0.7502 - accuracy: 0.7381 - val_loss: 0.9809 - val_accuracy: 0.6651\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 264s 5ms/step - loss: 0.6984 - accuracy: 0.7573 - val_loss: 0.8825 - val_accuracy: 0.6945\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 265s 5ms/step - loss: 0.6568 - accuracy: 0.7715 - val_loss: 0.9820 - val_accuracy: 0.6744\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 261s 5ms/step - loss: 0.6152 - accuracy: 0.7873 - val_loss: 0.9519 - val_accuracy: 0.6748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9cb5cd1f60>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size=128, epochs=10, validation_data = (previsores_teste, classe_teste), use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predição da base de teste e resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 19s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "resultado = classificador.evaluate(previsores_teste, classe_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9519048468589782, 0.6747999787330627]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
